{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da5b0823-fe3f-4e0a-b691-fecd989ebfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "628a387c-02b3-43ed-b24c-5417e6b380e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define network parametres\n",
    "\n",
    "# Network architecture parameters\n",
    "input_size = 8      # Input layer has 8 nodes\n",
    "hidden_size = 3     # Hidden layer has 3 nodes\n",
    "output_size = 8     # Output layer has 8 nodes\n",
    "\n",
    "# Learning rate\n",
    "learning_rate = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee4bbacc-82b5-4dc8-8a35-4d8c0dc4b9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Weights and Biases\n",
    "\n",
    "\n",
    "# Initialize weights with small random values\n",
    "W1 = np.random.randn(hidden_size, input_size) * 0.01  # Weights between input and hidden layers\n",
    "b1 = np.zeros((hidden_size, 1))                       # Bias for hidden layer\n",
    "\n",
    "W2 = np.random.randn(output_size, hidden_size) * 0.01 # Weights between hidden and output layers\n",
    "b2 = np.zeros((output_size, 1))                       # Bias for output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7897e74b-8ad3-4b6f-b715-aba44b94c49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Activation Functions\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be41efcf-60f9-4709-97f7-66c0068edb08",
   "metadata": {},
   "source": [
    "Weâ€™ll use the sigmoid function and its derivative for both the hidden and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3e8dc39-ccf9-4416-a94d-cba69f2fbe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Propagation Function\n",
    "def forward_propagation(X):\n",
    "    # Hidden layer\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = sigmoid(Z1)\n",
    "    \n",
    "    # Output layer\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "    \n",
    "    return Z1, A1, Z2, A2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f68b7b-a678-47ee-bf5d-1312723d559e",
   "metadata": {},
   "source": [
    "This function computes the activations for the hidden and output layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82ede402-1cb9-47ec-b77e-da4db732494e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward Propagation Function\n",
    "\n",
    "def backward_propagation(X, Y, Z1, A1, Z2, A2):\n",
    "    global W1, b1, W2, b2  # Use global variables to modify the weights and biases\n",
    "\n",
    "    # Compute the output layer error\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = np.dot(dZ2, A1.T)\n",
    "    db2 = np.sum(dZ2, axis=1, keepdims=True)\n",
    "    \n",
    "    # Backpropagate the error to the hidden layer\n",
    "    dA1 = np.dot(W2.T, dZ2)\n",
    "    dZ1 = dA1 * sigmoid_derivative(Z1)\n",
    "    dW1 = np.dot(dZ1, X.T)\n",
    "    db1 = np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    # Update weights and biases\n",
    "    W1 -= learning_rate * dW1\n",
    "    b1 -= learning_rate * db1\n",
    "    W2 -= learning_rate * dW2\n",
    "    b2 -= learning_rate * db2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ba4db9-a120-4738-8545-dc9b204eb295",
   "metadata": {},
   "source": [
    "This function calculates the gradients for each weight and bias and performs a gradient descent update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "431bb711-4448-4ff6-a683-4e1dd55adef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data: each example has seven 0s and one 1\n",
    "X_train = np.eye(input_size)  # Identity matrix gives each unit vector as a row\n",
    "Y_train = X_train.copy()      # Outputs should match inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1dc9aa-1165-421b-8315-d5371d514d5c",
   "metadata": {},
   "source": [
    "Create the 8 unique training examples and their corresponding labels (targets), which are the same as the inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8d3c95a-eeb1-4d19-8aac-64b035044abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function \n",
    "def train(X_train, Y_train, epochs=10000):\n",
    "    for epoch in range(epochs):\n",
    "        cost = 0\n",
    "        for X, Y in zip(X_train, Y_train):\n",
    "            # Reshape inputs and targets for matrix operations\n",
    "            X = X.reshape(-1, 1)\n",
    "            Y = Y.reshape(-1, 1)\n",
    "            \n",
    "            # Forward propagation\n",
    "            Z1, A1, Z2, A2 = forward_propagation(X)\n",
    "            \n",
    "            # Calculate cost for monitoring purposes\n",
    "            cost += np.sum((A2 - Y) ** 2) / 2  # Mean squared error\n",
    "            \n",
    "            # Backward propagation\n",
    "            backward_propagation(X, Y, Z1, A1, Z2, A2)\n",
    "\n",
    "        # Print the cost at regular intervals for monitoring\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f\"Epoch {epoch}, Cost: {cost / len(X_train)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52011f35-cd20-4d45-bb5c-3f3a120f401a",
   "metadata": {},
   "source": [
    "This function iteratively performs forward and backward propagation, updating weights at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02335c75-8add-4fc0-8481-4dc2780954c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_train):\n",
    "    print(\"\\nEvaluating the network...\")\n",
    "    for i, X in enumerate(X_train):\n",
    "        X = X.reshape(-1, 1)\n",
    "        Z1, A1, Z2, A2 = forward_propagation(X)\n",
    "        \n",
    "        # Normalize the predicted output by rounding to 0 or 1\n",
    "        normalized_output = (A2 >= 0.5).astype(int)\n",
    "        \n",
    "        print(f\"Input: {X.T}\")\n",
    "        print(f\"Predicted Output (Raw): {A2.T}\")\n",
    "        print(f\"Predicted Output (Normalized): {normalized_output.T}\")\n",
    "        print(f\"Target Output: {X.T}\")\n",
    "        print(f\"Hidden Layer Activations: {A1.T}\\n\")\n",
    "        print(\"-\" * 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69e38d3-e0a0-4e4a-99d2-263285358564",
   "metadata": {},
   "source": [
    "After training, evaluate the network on each of the 8 training examples to see how well it has learned the reproducing function. \n",
    "This also prints hidden layer activations and weights for interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c05f4443-334c-4f9e-b35f-2ad423441d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Cost: 0.01510437872077198\n",
      "Epoch 1000, Cost: 0.01152731526745082\n",
      "Epoch 2000, Cost: 0.00907415806764463\n",
      "Epoch 3000, Cost: 0.007321861384216741\n",
      "Epoch 4000, Cost: 0.006028337630612722\n",
      "Epoch 5000, Cost: 0.005047199610655038\n",
      "Epoch 6000, Cost: 0.00428587051750181\n",
      "Epoch 7000, Cost: 0.0036835642060757084\n",
      "Epoch 8000, Cost: 0.003199071657250611\n",
      "Epoch 9000, Cost: 0.002803675603005892\n",
      "\n",
      "Final Weights and Biases After Training:\n",
      "Weights from Input to Hidden Layer (W1):\n",
      " [[ 0.7647384  -2.22105116 -1.51803946  4.48331713  3.66642252 -5.21270141\n",
      "  -4.95597926  5.00951692]\n",
      " [-4.21187189 -4.4779626   4.72621822 -4.51647495  4.15408825 -1.68849364\n",
      "   3.63925971  2.32394686]\n",
      " [-4.61789475  3.71197417 -4.30049594  2.13127103  5.54787365 -2.45835848\n",
      "   2.66464629 -3.03556861]]\n",
      "Biases for Hidden Layer (b1):\n",
      " [[ 0.0618744 ]\n",
      " [-0.06125757]\n",
      " [-0.35977608]]\n",
      "Weights from Hidden to Output Layer (W2):\n",
      " [[  6.02106996  -9.5955226  -10.46963219]\n",
      " [ -7.49684207  -8.84409841   7.47732676]\n",
      " [ -6.98272192   9.10001144  -9.50594284]\n",
      " [  8.15745234  -8.23243076   4.50299256]\n",
      " [  5.1828747    5.0167194    5.91228742]\n",
      " [-11.25587952  -5.4653851   -7.07474805]\n",
      " [ -9.92473724   6.34444086   5.48214045]\n",
      " [  8.71803846   4.35217096  -7.47140643]]\n",
      "Biases for Output Layer (b2):\n",
      " [[ -1.23270557]\n",
      " [ -3.02909052]\n",
      " [ -4.6649066 ]\n",
      " [ -8.89836159]\n",
      " [-13.44301402]\n",
      " [  3.92047267]\n",
      " [ -7.96968106]\n",
      " [ -9.52960308]]\n",
      "\n",
      "Evaluating the network...\n",
      "Input: [[1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Predicted Output (Raw): [[9.40039341e-01 2.44857553e-04 7.77207629e-05 3.53632283e-02\n",
      "  5.95765834e-05 1.74109846e-02 3.93187017e-07 3.05814928e-02]]\n",
      "Predicted Output (Normalized): [[1 0 0 0 0 0 0 0]]\n",
      "Target Output: [[1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "Hidden Layer Activations: [[0.69563825 0.0137465  0.00684294]]\n",
      "\n",
      "--------------------------------------------------\n",
      "Input: [[0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "Predicted Output (Raw): [[1.98637709e-05 9.65313676e-01 5.16752845e-07 2.20838987e-02\n",
      "  7.91039551e-04 1.57123755e-02 2.57585860e-02 1.37424627e-07]]\n",
      "Predicted Output (Normalized): [[0 1 0 0 0 0 0 0]]\n",
      "Target Output: [[0. 1. 0. 0. 0. 0. 0. 0.]]\n",
      "Hidden Layer Activations: [[0.1034768  0.01056884 0.96617674]]\n",
      "\n",
      "--------------------------------------------------\n",
      "Input: [[0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "Predicted Output (Raw): [[6.13699325e-05 1.96922326e-06 9.49834054e-01 1.91275720e-07\n",
      "  5.88212189e-04 2.44060983e-02 2.90469194e-02 2.55831318e-02]]\n",
      "Predicted Output (Normalized): [[0 0 1 0 0 0 0 0]]\n",
      "Target Output: [[0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "Hidden Layer Activations: [[0.18905457 0.99066828 0.00937516]]\n",
      "\n",
      "--------------------------------------------------\n",
      "Input: [[0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Predicted Output (Raw): [[1.31211677e-02 1.55703460e-02 3.05686442e-09 9.49697252e-01\n",
      "  3.87666249e-02 1.64275191e-06 2.17099719e-06 7.13743487e-04]]\n",
      "Predicted Output (Normalized): [[0 0 0 1 0 0 0 0]]\n",
      "Target Output: [[0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Hidden Layer Activations: [[0.98949342 0.01017361 0.85464348]]\n",
      "\n",
      "--------------------------------------------------\n",
      "Input: [[0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "Predicted Output (Raw): [[2.49840870e-07 9.04702189e-06 6.22888408e-06 1.04397492e-02\n",
      "  9.19238148e-01 3.45873850e-09 2.54899543e-03 1.52864418e-02]]\n",
      "Predicted Output (Normalized): [[0 0 0 0 1 0 0 0]]\n",
      "Target Output: [[0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "Hidden Layer Activations: [[0.97653033 0.98358213 0.99444838]]\n",
      "\n",
      "--------------------------------------------------\n",
      "Input: [[0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "Predicted Output (Raw): [[3.88324158e-02 1.86965930e-02 1.99710533e-02 5.45325384e-05\n",
      "  4.38587903e-06 9.33865506e-01 1.13673921e-03 9.55330982e-05]]\n",
      "Predicted Output (Normalized): [[0 0 0 0 0 1 0 0]]\n",
      "Target Output: [[0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "Hidden Layer Activations: [[0.00576123 0.14807858 0.05635205]]\n",
      "\n",
      "--------------------------------------------------\n",
      "Input: [[0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "Predicted Output (Raw): [[1.97528987e-09 7.46800992e-03 1.09042259e-02 2.89660704e-06\n",
      "  4.11640453e-02 3.65815745e-04 9.57441067e-01 5.99564716e-06]]\n",
      "Predicted Output (Normalized): [[0 0 0 0 0 0 1 0]]\n",
      "Target Output: [[0. 0. 0. 0. 0. 0. 1. 0.]]\n",
      "Hidden Layer Activations: [[0.00743492 0.97282752 0.90927959]]\n",
      "\n",
      "--------------------------------------------------\n",
      "Input: [[0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Predicted Output (Raw): [[1.36554605e-02 1.18959465e-08 2.48377434e-02 3.02803920e-04\n",
      "  2.77383406e-02 3.93750181e-06 6.73434258e-06 9.44466474e-01]]\n",
      "Predicted Output (Normalized): [[0 0 0 0 0 0 0 1]]\n",
      "Target Output: [[0. 0. 0. 0. 0. 0. 0. 1.]]\n",
      "Hidden Layer Activations: [[0.99376543 0.90573948 0.03244127]]\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Print Learned Weights and Run the Training and Evaluation\n",
    "# Train the network\n",
    "train(X_train, Y_train, epochs=10000)\n",
    "\n",
    "# Print the final learned weights and biases\n",
    "print(\"\\nFinal Weights and Biases After Training:\")\n",
    "print(\"Weights from Input to Hidden Layer (W1):\\n\", W1)\n",
    "print(\"Biases for Hidden Layer (b1):\\n\", b1)\n",
    "print(\"Weights from Hidden to Output Layer (W2):\\n\", W2)\n",
    "print(\"Biases for Output Layer (b2):\\n\", b2)\n",
    "\n",
    "# Evaluate the network on the training examples\n",
    "evaluate(X_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ab9162-2434-4cae-b398-d8445bc9518a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
